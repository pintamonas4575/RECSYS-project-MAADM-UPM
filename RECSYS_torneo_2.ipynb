{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8eeafe4",
   "metadata": {},
   "source": [
    "# **Filtrado basado en contenido**\n",
    "\n",
    "Álvaro Fraile, Jaime Álvarez, Alejandro Mendoza\n",
    "\n",
    "https://www.kaggle.com/competitions/recsys-filtrado-basado-en-contenido-2425"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e441b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f10d4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\workspace\\RECSYS-project-MAADM-UPM\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1edd6f",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b92c7",
   "metadata": {},
   "source": [
    "### Negocios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27bef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negocios initial memory usage: 31.01 MB\n",
      "Negocios final memory usage: 19.24 MB\n",
      "***** Preprocesamiento negocios: 0 minutos y 0 segundos *****\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "negocios_df = pd.read_csv('data/recsys-filtrado-basado-en-contenido-24-25/negocios.csv')\n",
    "initial_memory = negocios_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'Negocios initial memory usage: {initial_memory:.2f} MB')\n",
    "\n",
    "negocios_df.drop(columns=['address', 'postal_code', 'is_open', 'hours'], inplace=True)\n",
    "for col in negocios_df.select_dtypes(include=['object']):\n",
    "    negocios_df[col] = negocios_df[col].astype(\"category\")\n",
    "negocios_df['latitude'] = negocios_df['latitude'].astype('float16')\n",
    "negocios_df['longitude'] = negocios_df['longitude'].astype('float16')\n",
    "negocios_df['stars'] = negocios_df['stars'].astype('float16')\n",
    "negocios_df['review_count'] = negocios_df['review_count'].astype('int16')\n",
    "\n",
    "final_memory = negocios_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'Negocios final memory usage: {final_memory:.2f} MB')\n",
    "\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** Preprocesamiento negocios: {int(minutos)} minutos y {int(segundos)} segundos *****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8697ab",
   "metadata": {},
   "source": [
    "### Usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7456d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_12552\\57253039.py:3: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  usuarios_df = pd.read_csv('data/recsys-filtrado-basado-en-contenido-24-25/usuarios.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negocios initial memory usage: 1265.39 MB\n",
      "Negocios final memory usage: 1114.46 MB\n",
      "***** Preprocesamiento usuarios: 0 minutos y 9 segundos *****\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "usuarios_df = pd.read_csv('data/recsys-filtrado-basado-en-contenido-24-25/usuarios.csv')\n",
    "initial_memory = usuarios_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'Negocios initial memory usage: {initial_memory:.2f} MB')\n",
    "\n",
    "usuarios_df.drop(columns=['elite', 'yelping_since'], inplace=True)\n",
    "usuarios_df['user_id'] = usuarios_df['user_id'].astype('string')\n",
    "usuarios_df['name'] = usuarios_df['name'].astype('category')\n",
    "usuarios_df['friends'] = usuarios_df['friends'].astype('category')\n",
    "usuarios_df['useful'] = usuarios_df['useful'].astype('int32')\n",
    "usuarios_df['funny'] = usuarios_df['funny'].astype('int32')\n",
    "usuarios_df['cool'] = usuarios_df['cool'].astype('int32')\n",
    "usuarios_df['average_stars'] = usuarios_df['average_stars'].astype('float16')\n",
    "for col in usuarios_df.select_dtypes(include=['int64']):\n",
    "    usuarios_df[col] = usuarios_df[col].astype('uint16')\n",
    "\n",
    "final_memory = usuarios_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'Negocios final memory usage: {final_memory:.2f} MB')\n",
    "\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** Preprocesamiento usuarios: {int(minutos)} minutos y {int(segundos)} segundos *****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ecacb",
   "metadata": {},
   "source": [
    "### Train_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e23a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reviews initial memory usage: 859.81 MB\n",
      "Train reviews final memory usage: 727.39 MB\n",
      "***** Preprocesamiento train reviews: 0 minutos y 7 segundos *****\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_reviews_df = pd.read_csv('data/recsys-filtrado-basado-en-contenido-24-25/train_reviews.csv')\n",
    "initial_memory = train_reviews_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'Train reviews initial memory usage: {initial_memory:.2f} MB')\n",
    "\n",
    "train_reviews_df.drop(columns=['date'], inplace=True)\n",
    "train_reviews_df['review_id'] = train_reviews_df['review_id'].astype('string')\n",
    "train_reviews_df['user_id'] = train_reviews_df['user_id'].astype('category')\n",
    "train_reviews_df['business_id'] = train_reviews_df['business_id'].astype('category')\n",
    "train_reviews_df['text'] = train_reviews_df['text'].astype('string')\n",
    "\n",
    "final_memory = train_reviews_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'Train reviews final memory usage: {final_memory:.2f} MB')\n",
    "\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** Preprocesamiento train reviews: {int(minutos)} minutos y {int(segundos)} segundos *****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e232282",
   "metadata": {},
   "source": [
    "### Test_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ddbb3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reviews initial memory usage: 365.37 MB\n",
      "Train reviews final memory usage: 314.81 MB\n",
      "***** Preprocesamiento test reviews: 0 minutos y 3 segundos *****\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "test_reviews_df = pd.read_csv('data/recsys-filtrado-basado-en-contenido-24-25/test_reviews.csv')\n",
    "initial_memory = test_reviews_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'Train reviews initial memory usage: {initial_memory:.2f} MB')\n",
    "\n",
    "test_reviews_df.drop(columns=['date'], inplace=True)\n",
    "test_reviews_df['review_id'] = test_reviews_df['review_id'].astype('string')\n",
    "test_reviews_df['user_id'] = test_reviews_df['user_id'].astype('category')\n",
    "test_reviews_df['business_id'] = test_reviews_df['business_id'].astype('category')\n",
    "test_reviews_df['text'] = test_reviews_df['text'].astype('string')\n",
    "\n",
    "final_memory = test_reviews_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'Train reviews final memory usage: {final_memory:.2f} MB')\n",
    "\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** Preprocesamiento test reviews: {int(minutos)} minutos y {int(segundos)} segundos *****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba6830",
   "metadata": {},
   "source": [
    "## **Submission DataFrame skeleton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bfafd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = test_reviews_df[['review_id']].copy() # dataframe with review_id column\n",
    "global_avg = train_reviews_df['stars'].mean() # global average rating value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb7024",
   "metadata": {},
   "source": [
    "## Aproximación 1 - Media del negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ea3cc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of avg_ratings: 30064\n",
      "Length of negocios_df: 30069\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>avg_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--7PUidqRWpRSpXebiyxTg</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--ARBQr1WMsTWiwOKOj-FQ</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--LC8cIrALInl2vyo701tg</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--N9yp3ZWqQIm7DqKRvorg</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--S43ruInmIsGrnnkmavRw</td>\n",
       "      <td>3.380952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  avg_stars\n",
       "0  --7PUidqRWpRSpXebiyxTg   1.900000\n",
       "1  --ARBQr1WMsTWiwOKOj-FQ   4.666667\n",
       "2  --LC8cIrALInl2vyo701tg   4.600000\n",
       "3  --N9yp3ZWqQIm7DqKRvorg   2.500000\n",
       "4  --S43ruInmIsGrnnkmavRw   3.380952"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average rating for each business\n",
    "avg_ratings = train_reviews_df.groupby('business_id', observed=True)['stars'].mean().reset_index()\n",
    "avg_ratings.columns = ['business_id', 'avg_stars']\n",
    "print(\"Length of avg_ratings:\", len(avg_ratings))\n",
    "print(\"Length of negocios_df:\", len(negocios_df))\n",
    "avg_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd907af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414765/414765 [01:40<00:00, 4123.59it/s]\n"
     ]
    }
   ],
   "source": [
    "output_df_1 = output_df.copy()\n",
    "for index, review in tqdm(test_reviews_df.iterrows(), total=len(test_reviews_df)):\n",
    "    output_df_1.loc[index, 'stars'] = (\n",
    "        avg_ratings.loc[avg_ratings['business_id'] == review['business_id'], 'avg_stars'].values[0]\n",
    "        if review['business_id'] in avg_ratings['business_id'].values else global_avg\n",
    "    )\n",
    "\n",
    "output_df_1.to_csv('results_tournament_2/submission_business_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd2bc3",
   "metadata": {},
   "source": [
    "MAE Público obtenido: \n",
    "* Usando 3 como default: **1.0433**\n",
    "* Usando media global como default: **1.0433**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24a2b4",
   "metadata": {},
   "source": [
    "## Aproximación 1.1 - Con redondeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "780e60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_2 = output_df_1.copy() \n",
    "output_df_2['stars'] = output_df_2['stars'].round()\n",
    "output_df_2.to_csv('results_tournament_2/submission_business_avg_rounded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96f8b2",
   "metadata": {},
   "source": [
    "MAE Público obtenido con redondeo: **1.0286**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0788d1",
   "metadata": {},
   "source": [
    "## Aproximación 2 - Embeddings con TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee5e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizando con TF-IDF...\n",
      "***** TF-IDF vectorization: 0 minutes 34 seconds *****\n",
      "Calculando similitud...\n",
      "***** Cosine similarity: 2 minutes 24 seconds *****\n",
      "Creando diccionario de ratings por usuario...\n",
      "***** User ratings dictionary: 4 minutes 5 seconds *****\n",
      "Prediciendo ratings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414765/414765 [00:54<00:00, 7542.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Total time: 8 minutes 0 seconds *****\n"
     ]
    }
   ],
   "source": [
    "total_time = time.time()\n",
    "\n",
    "# Paso 1: Agrupar reviews por negocio\n",
    "business_reviews = train_reviews_df.groupby('business_id', observed=True)['text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Paso 2: Vectorizar con TF-IDF\n",
    "print(\"Vectorizando con TF-IDF...\")\n",
    "start = time.time()\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(business_reviews['text'])\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** TF-IDF vectorization: {int(minutos)} minutes {int(segundos)} seconds *****\")\n",
    "\n",
    "# Paso 3: Calcular similitud entre negocios\n",
    "print(\"Calculando similitud...\")\n",
    "start = time.time()\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** Cosine similarity: {int(minutos)} minutes {int(segundos)} seconds *****\")\n",
    "\n",
    "# Paso 4: Índice para acceder por business_id\n",
    "business_indices = pd.Series(business_reviews.index, index=business_reviews['business_id'])\n",
    "\n",
    "# Paso 5: Crear un diccionario de ratings por usuario\n",
    "print(\"Creando diccionario de ratings por usuario...\")\n",
    "start = time.time()\n",
    "user_ratings = train_reviews_df.groupby('user_id', observed=True)\n",
    "user_ratings = user_ratings.apply(lambda x: x[['business_id', 'stars']].set_index('business_id').to_dict()['stars'], include_groups=False).to_dict()\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** User ratings dictionary: {int(minutos)} minutes {int(segundos)} seconds *****\")\n",
    "\n",
    "# Paso 6: Función para predecir rating\n",
    "def predict_rating(user_id: str, target_business_id: str) -> float:\n",
    "    if user_id not in user_ratings or target_business_id not in business_indices:\n",
    "        return global_avg\n",
    "\n",
    "    rated_items = user_ratings[user_id]\n",
    "    similarities = []\n",
    "    ratings = []\n",
    "\n",
    "    target_idx = business_indices[target_business_id]\n",
    "\n",
    "    for rated_business_id, rating in rated_items.items():\n",
    "        if rated_business_id in business_indices:\n",
    "            rated_idx = business_indices[rated_business_id]\n",
    "            sim = cosine_sim[target_idx, rated_idx]\n",
    "            if sim > 0:  # Considerar solo similares positivos\n",
    "                similarities.append(sim)\n",
    "                ratings.append(rating)\n",
    "\n",
    "    if not similarities:\n",
    "        return global_avg # No hay similitud con los ítems que ha valorado\n",
    "\n",
    "    # Promedio ponderado\n",
    "    weighted_avg = np.dot(similarities, ratings) / np.sum(similarities)\n",
    "    return weighted_avg\n",
    "\n",
    "# Paso 7: Predecir ratings\n",
    "print(\"Prediciendo ratings...\")\n",
    "output_df_3 = output_df.copy()\n",
    "for index, review in tqdm(test_reviews_df.iterrows(), total=len(test_reviews_df)):\n",
    "    output_df_3.loc[index, 'stars'] = predict_rating(review['user_id'], review['business_id'])\n",
    "\n",
    "total_minutes, total_seconds = divmod(time.time() - total_time, 60)\n",
    "print(f\"***** Total time: {int(total_minutes)} minutes {int(total_seconds)} seconds *****\")\n",
    "\n",
    "output_df_3['stars'] = output_df_3['stars'].round()\n",
    "output_df_3.to_csv('results_tournament_2/submission_tfidf_rounded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00896ad5",
   "metadata": {},
   "source": [
    "MAE público obtenido con TFIDF: **1.1597**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e9e0e",
   "metadata": {},
   "source": [
    "## Aproximación 3 - Embeddings con Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e86aaad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "Cargando modelo de sentence-transformers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\workspace\\RECSYS-project-MAADM-UPM\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aleja\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Carga de modelo: 0 minutos 7 segundos *****\n",
      "Vectorizando con sentence-transformers...\n",
      "***** Vectorización: 1 minutos 23 segundos *****\n",
      "Calculando similitud...\n",
      "***** Cosine similarity: 0 minutos 1 segundos *****\n",
      "Creando diccionario de ratings por usuario...\n",
      "***** User ratings dictionary: 4 minutos 14 segundos *****\n",
      "Prediciendo ratings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414765/414765 [00:57<00:00, 7207.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Total time: 6 minutes 45 seconds *****\n"
     ]
    }
   ],
   "source": [
    "total_time = time.time()\n",
    "\n",
    "# Paso 1: Agrupar reviews por negocio\n",
    "business_reviews = train_reviews_df.groupby('business_id', observed=True)['text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Paso 2: Vectorizar con SentenceTransformer en GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "print(\"Cargando modelo de sentence-transformers...\")\n",
    "start = time.time()\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** Carga de modelo: {int(minutos)} minutos {int(segundos)} segundos *****\")\n",
    "\n",
    "print(\"Vectorizando con sentence-transformers...\")\n",
    "start = time.time()\n",
    "embeddings = model.encode(business_reviews['text'].tolist(), convert_to_tensor=True, device=device)\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** Vectorización: {int(minutos)} minutos {int(segundos)} segundos *****\")\n",
    "\n",
    "# Paso 3: Calcular similitud entre negocios\n",
    "print(\"Calculando similitud...\")\n",
    "start = time.time()\n",
    "cosine_sim = util.pytorch_cos_sim(embeddings, embeddings).cpu().numpy()  # Para usarlo como matriz normal\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** Cosine similarity: {int(minutos)} minutos {int(segundos)} segundos *****\")\n",
    "\n",
    "# Paso 4: Índice para acceder por business_id\n",
    "business_indices = pd.Series(business_reviews.index, index=business_reviews['business_id'])\n",
    "\n",
    "# Paso 5: Crear un diccionario de ratings por usuario\n",
    "print(\"Creando diccionario de ratings por usuario...\")\n",
    "start = time.time()\n",
    "user_ratings = train_reviews_df.groupby('user_id', observed=True)\n",
    "user_ratings = user_ratings.apply(lambda x: x[['business_id', 'stars']].set_index('business_id').to_dict()['stars'], include_groups=False).to_dict()\n",
    "minutos, segundos = divmod(time.time() - start, 60)\n",
    "print(f\"***** User ratings dictionary: {int(minutos)} minutos {int(segundos)} segundos *****\")\n",
    "\n",
    "# Paso 6: Función para predecir rating\n",
    "def predict_rating(user_id: str, target_business_id: str) -> float:\n",
    "    if user_id not in user_ratings or target_business_id not in business_indices:\n",
    "        return global_avg \n",
    "    rated_items = user_ratings[user_id]\n",
    "    similarities = []\n",
    "    ratings = []\n",
    "\n",
    "    target_idx = business_indices[target_business_id]\n",
    "\n",
    "    for rated_business_id, rating in rated_items.items():\n",
    "        if rated_business_id in business_indices:\n",
    "            rated_idx = business_indices[rated_business_id]\n",
    "            sim = cosine_sim[target_idx, rated_idx]\n",
    "            if sim > 0:  # Considerar solo similares positivos\n",
    "                similarities.append(sim)\n",
    "                ratings.append(rating)\n",
    "\n",
    "    if not similarities:\n",
    "        return global_avg  # No hay similitud con los ítems que ha valorado\n",
    "\n",
    "    # Promedio ponderado\n",
    "    weighted_avg = np.dot(similarities, ratings) / np.sum(similarities)\n",
    "    return weighted_avg\n",
    "\n",
    "# Paso 7: Predecir ratings\n",
    "print(\"Prediciendo ratings...\")\n",
    "output_df_4 = output_df.copy()\n",
    "for index, review in tqdm(test_reviews_df.iterrows(), total=len(test_reviews_df)):\n",
    "    output_df_4.loc[index, 'stars'] = predict_rating(review['user_id'], review['business_id'])\n",
    "\n",
    "total_minutes, total_seconds = divmod(time.time() - total_time, 60)\n",
    "print(f\"***** Total time: {int(total_minutes)} minutes {int(total_seconds)} seconds *****\")\n",
    "\n",
    "output_df_4['stars'] = output_df_4['stars'].round()\n",
    "output_df_4.to_csv('results_tournament_2/submission_tfidf_rounded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82faf36f",
   "metadata": {},
   "source": [
    "MAE público obtenido con Sentence Transformers: **1.1594**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b48f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
